{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "6Gb-UDVPiJD_",
    "ExecuteTime": {
     "end_time": "2025-01-01T16:23:31.036270Z",
     "start_time": "2025-01-01T16:23:31.030766Z"
    }
   },
   "source": [
    "import os\n",
    "from random import shuffle\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from termcolor import colored\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, \\\n",
    "    TrainingArguments, Trainer"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BImUvHL9iJEE",
    "outputId": "be4e1af8-be2e-401a-c39d-72d9b86906c6",
    "ExecuteTime": {
     "end_time": "2025-01-01T15:57:48.483964Z",
     "start_time": "2025-01-01T15:57:48.421089Z"
    }
   },
   "source": [
    "CLASSES = {\n",
    "    'yes': 0,\n",
    "    'irrelevant': 1,\n",
    "    'no': 2,\n",
    "}\n",
    "STORY_FILE = 'dataset/story.txt'\n",
    "DATASET_PATH = 'dataset/'\n",
    "MODEL_NAME = \"cross-encoder/nli-deberta-v3-base\"\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 4\n",
    "LEARNING_RATE = 2e-5\n",
    "MAX_LENGTH = 512\n",
    "DEVICE = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "DEVICE"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmMXb7njiJEF"
   },
   "source": [
    "Here we define the tokenizer and the model using the handy `transformer` library from *HuggingFace*."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QXcFjrZkiJEG",
    "outputId": "4c3a5ff5-57d8-4a81-c7af-39324259db84"
   },
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\n",
    "model = model.to(DEVICE)\n",
    "pass"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75F-VmBRiJEH"
   },
   "source": [
    "Next, we load the data set and split it into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122,
     "referenced_widgets": [
      "d4eff6637f934e6e857ea81f1b2ccb06",
      "4ed48493bc7240c1b5939c7eeaefc483",
      "ff675ee657e74328b8311b0bd0001790",
      "3208741436df4f07a8652362a451cdc5",
      "72f1364c8b4747c9a424f9e5070f233c",
      "5a93afd633054cf5b4ae6b1d9aa75ba1",
      "bc4a9f166c674e15a05d2093c4378e7c",
      "5ff480d6e3464f339ede102fc5bcb078",
      "0a39ec610ffc4a95a03596e144a0f905",
      "2fd0d94669c34ac2b2825fbf166202ec",
      "83b84f2fa4b440bea43222657938b3c2"
     ]
    },
    "id": "nuLS-N4liJEI",
    "outputId": "692b0ed4-ba6d-43eb-fc1b-b7a701ba190a",
    "ExecuteTime": {
     "end_time": "2025-01-01T15:58:28.161754Z",
     "start_time": "2025-01-01T15:58:26.013742Z"
    }
   },
   "source": [
    "story = open(STORY_FILE).read().replace(\"\\n\\n\", \"\\n\").replace(\"\\n\", \" \").strip()\n",
    "\n",
    "dataset: list[dict] = []\n",
    "for file in CLASSES.keys():\n",
    "    with open(os.path.join(DATASET_PATH, f'{file}.txt')) as f:\n",
    "        lines = f.readlines()[:]\n",
    "        print(f'Read {len(lines)} \"{file}\" questions')\n",
    "        dataset.extend(map(lambda e: {'question': e.replace(\n",
    "            '\\n', '').strip(), 'answer': CLASSES[file]}, lines))\n",
    "\n",
    "shuffle(dataset)\n",
    "\n",
    "\n",
    "def preprocess(sample):\n",
    "    inputs = tokenizer(\n",
    "        story,\n",
    "        sample[\"question\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "    inputs[\"label\"] = sample[\"answer\"]\n",
    "    return inputs\n",
    "\n",
    "\n",
    "hf_dataset = Dataset.from_list(dataset)\n",
    "tokenized_dataset = hf_dataset.map(preprocess, remove_columns=[\"question\"])\n",
    "\n",
    "split = tokenized_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = tokenized_dataset  #split[\"train\"]\n",
    "eval_dataset = split[\"test\"]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 651 \"yes\" questions\n",
      "Read 658 \"irrelevant\" questions\n",
      "Read 653 \"no\" questions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1962 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8e2f12d9ead403caa6558fae7a58d06"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "id": "qPGdraniiJEI"
   },
   "cell_type": "markdown",
   "source": [
    "For Ä , look at https://discuss.huggingface.co/t/bpe-tokenizers-and-spaces-before-words/475"
   ]
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5rBUMe3uiJEJ",
    "outputId": "9637bdb7-7aef-4b3b-cfac-2f1f0dd9011d"
   },
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    report_to='none',\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    eval_accumulation_steps=10,\n",
    "    disable_tqdm=False\n",
    ")\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Executing the training (~ 1h $\\times$ epoch using `cross-encoder/nli-deberta-v3-base`)."
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95
    },
    "id": "n_2awqrSiJEJ",
    "outputId": "ac9f0dc5-b9b3-4996-e16d-f4630d80c187"
   },
   "source": "trainer.train()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Forcibly saving the meodel in memory."
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FE4gUjFziJEK"
   },
   "source": [
    "checkpoint_path = \"checkpoint/deberta_seagull_ep_4_lr_2e-5_train_0.09_test_0.23_half\"\n",
    "model.save_pretrained(checkpoint_path)\n",
    "tokenizer.save_pretrained(checkpoint_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Loading model and tokenizer from a checkpoint. "
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T16:51:58.705249Z",
     "start_time": "2025-01-01T16:51:57.554128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "checkpoint_path = \"checkpoint/deberta_seagull_ep_4_lr_2e-5_train_0.09_test_0.23_half\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint_path).to(DEVICE)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluation over the test set."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T15:58:44.013332Z",
     "start_time": "2025-01-01T15:58:37.356278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"results\",\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_dir=\"logs\",\n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    ")\n",
    "tester = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "results = tester.evaluate(eval_dataset=eval_dataset)\n",
    "results"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MrPio\\AppData\\Local\\Temp\\ipykernel_25796\\1670004140.py:8: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  tester = Trainer(\n",
      "[codecarbon ERROR @ 16:58:37] Error: Another instance of codecarbon is already running. Turn off the other instance to be able to run this one. Exiting.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:05]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.152888223528862,\n",
       " 'eval_model_preparation_time': 0.0017,\n",
       " 'eval_accuracy': 0.9695431472081218,\n",
       " 'eval_runtime': 6.3388,\n",
       " 'eval_samples_per_second': 31.078,\n",
       " 'eval_steps_per_second': 2.051}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Inference of a single question."
  },
  {
   "metadata": {
    "id": "T1o0dWmriJEK",
    "ExecuteTime": {
     "end_time": "2025-01-01T16:52:03.380368Z",
     "start_time": "2025-01-01T16:52:02.017288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "questions = [(\"Albert shoot himself for a reason\", 0),\n",
    "             ('Lucy is an ugly woman', 1),\n",
    "             ('Albert has a wife', 0),\n",
    "             ('Dave has a watch on his wrist', 1),\n",
    "             ('Time has come for Miyamoto Musashi to die honorably', 1),\n",
    "             ('Someone brought Albert and Dave on the pier', 0),\n",
    "             ('Albert and Dave came to the pier on their own', 2),\n",
    "             ('Politics is important to unravel the mistery of this story', 2),\n",
    "             ('Politics is important for this story', 2),\n",
    "             ('Something really sad happened to Albert and Dave before coming to the pier', 0),\n",
    "             ('A friend of Albert and Dave brought them to the pier', 2),\n",
    "             ('A pirate brought Albert and Dave to the pier', 2),\n",
    "             ('A soldier brought Albert and Dave to the pier', 2),\n",
    "             ('A communist brought Albert and Dave to the pier', 2),\n",
    "             ('A sailor helped Albert and Dave to the pier', 0),\n",
    "             ('Albert ordered spaghetti together with the seagull meat', 2),\n",
    "             ('Dave was hungry', 1),\n",
    "             ('Dave is married', 1),\n",
    "             ('Albert and Dave were alone before coming to the pier', 2),\n",
    "             ('Albert and Dave were on an island before the pier', 0),\n",
    "             ('Dave suspected that Albert would kill himself', 0),\n",
    "             ('There were seagulls flying over at the pier', 1),\n",
    "             ('The seagull meat that Albert ordered tasted good', 1),\n",
    "             ('Albert put salt on the meat before eating it', 1),\n",
    "             ('cancer is the cause of Albert\\'s death', 2),\n",
    "             ('Dave was happy that Albert decided to kill himself', 2),\n",
    "             ('Dave secretly hated Albert', 2),\n",
    "             ('Dave secretly loved Lucy', 2),\n",
    "             ('Albert was happy about Lucy\\'s death', 2),\n",
    "             ('The seagull meat was on the menu', 0),\n",
    "             ('The cook is really talented', 1),\n",
    "             ]\n",
    "correct = 0\n",
    "for question in questions:\n",
    "    inputs = tokenizer(story, question[0], truncation=True, padding=True, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        prediction = torch.argmax(outputs.logits, dim=-1)\n",
    "    if prediction.item() == question[1]:\n",
    "        correct += 1\n",
    "    print(colored(\n",
    "        f'[{question[0]}] ---> {np.round(torch.softmax(outputs.logits, 1).squeeze().cpu().numpy(), 3)} ({[key for key, value in CLASSES.items() if value == prediction.item()][0]})',\n",
    "        'green' if prediction.item() == question[1] else 'red'))\n",
    "print(f'Accuracy: {correct}/{len(questions)} ->', round(correct / len(questions), 4))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m[Albert shoot himself for a reason] ---> [0.595 0.068 0.337] (yes)\u001B[0m\n",
      "\u001B[32m[Lucy is an ugly woman] ---> [0.003 0.989 0.008] (irrelevant)\u001B[0m\n",
      "\u001B[32m[Albert has a wife] ---> [0.448 0.311 0.241] (yes)\u001B[0m\n",
      "\u001B[32m[Dave has a watch on his wrist] ---> [0.    0.999 0.001] (irrelevant)\u001B[0m\n",
      "\u001B[31m[Time has come for Miyamoto Musashi to die honorably] ---> [0.56  0.103 0.336] (yes)\u001B[0m\n",
      "\u001B[32m[Someone brought Albert and Dave on the pier] ---> [0.941 0.013 0.046] (yes)\u001B[0m\n",
      "\u001B[32m[Albert and Dave came to the pier on their own] ---> [0.002 0.005 0.992] (no)\u001B[0m\n",
      "\u001B[31m[Politics is important to unravel the mistery of this story] ---> [0.99  0.001 0.008] (yes)\u001B[0m\n",
      "\u001B[32m[Politics is important for this story] ---> [0.006 0.022 0.972] (no)\u001B[0m\n",
      "\u001B[32m[Something really sad happened to Albert and Dave before coming to the pier] ---> [1. 0. 0.] (yes)\u001B[0m\n",
      "\u001B[32m[A friend of Albert and Dave brought them to the pier] ---> [0.    0.004 0.996] (no)\u001B[0m\n",
      "\u001B[32m[A pirate brought Albert and Dave to the pier] ---> [0.    0.001 0.998] (no)\u001B[0m\n",
      "\u001B[32m[A soldier brought Albert and Dave to the pier] ---> [0.    0.004 0.996] (no)\u001B[0m\n",
      "\u001B[32m[A communist brought Albert and Dave to the pier] ---> [0.    0.001 0.998] (no)\u001B[0m\n",
      "\u001B[32m[A sailor helped Albert and Dave to the pier] ---> [0.996 0.001 0.003] (yes)\u001B[0m\n",
      "\u001B[32m[Albert ordered spaghetti together with the seagull meat] ---> [0.322 0.002 0.676] (no)\u001B[0m\n",
      "\u001B[32m[Dave was hungry] ---> [0.072 0.887 0.041] (irrelevant)\u001B[0m\n",
      "\u001B[31m[Dave is married] ---> [0.943 0.02  0.037] (yes)\u001B[0m\n",
      "\u001B[32m[Albert and Dave were alone before coming to the pier] ---> [0.098 0.07  0.831] (no)\u001B[0m\n",
      "\u001B[32m[Albert and Dave were on an island before the pier] ---> [0.987 0.002 0.011] (yes)\u001B[0m\n",
      "\u001B[32m[Dave suspected that Albert would kill himself] ---> [0.987 0.    0.012] (yes)\u001B[0m\n",
      "\u001B[32m[There were seagulls flying over at the pier] ---> [0.    0.999 0.001] (irrelevant)\u001B[0m\n",
      "\u001B[32m[The seagull meat that Albert ordered tasted good] ---> [0.019 0.89  0.091] (irrelevant)\u001B[0m\n",
      "\u001B[32m[Albert put salt on the meat before eating it] ---> [0.001 0.985 0.014] (irrelevant)\u001B[0m\n",
      "\u001B[32m[cancer is the cause of Albert's death] ---> [0.029 0.    0.971] (no)\u001B[0m\n",
      "\u001B[32m[Dave was happy that Albert decided to kill himself] ---> [0.475 0.001 0.525] (no)\u001B[0m\n",
      "\u001B[32m[Dave secretly hated Albert] ---> [0.    0.002 0.997] (no)\u001B[0m\n",
      "\u001B[32m[Dave secretly loved Lucy] ---> [0.005 0.009 0.986] (no)\u001B[0m\n",
      "\u001B[31m[Albert was happy about Lucy's death] ---> [0.999 0.    0.001] (yes)\u001B[0m\n",
      "\u001B[32m[The seagull meat was on the menu] ---> [0.996 0.001 0.003] (yes)\u001B[0m\n",
      "\u001B[32m[The cook is really talented] ---> [0.    0.997 0.003] (irrelevant)\u001B[0m\n",
      "Accuracy: 27/31 -> 0.871\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Publish the model on HuggingFace."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T16:57:57.506505Z",
     "start_time": "2025-01-01T16:52:48.240102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.half()\n",
    "model.push_to_hub(\"TheSeagullStory-nli-deberta-v3-base\", use_auth_token='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')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/369M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82582220e5784008b25287750cc7e569"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/MrPio/TheSeagullStory-nli-deberta-v3-base/commit/4223619e63238e3b1f73cec22849a61d84318037', commit_message='Upload DebertaV2ForSequenceClassification', commit_description='', oid='4223619e63238e3b1f73cec22849a61d84318037', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "d4eff6637f934e6e857ea81f1b2ccb06": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4ed48493bc7240c1b5939c7eeaefc483",
       "IPY_MODEL_ff675ee657e74328b8311b0bd0001790",
       "IPY_MODEL_3208741436df4f07a8652362a451cdc5"
      ],
      "layout": "IPY_MODEL_72f1364c8b4747c9a424f9e5070f233c"
     }
    },
    "4ed48493bc7240c1b5939c7eeaefc483": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a93afd633054cf5b4ae6b1d9aa75ba1",
      "placeholder": "â",
      "style": "IPY_MODEL_bc4a9f166c674e15a05d2093c4378e7c",
      "value": "Map:â100%"
     }
    },
    "ff675ee657e74328b8311b0bd0001790": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ff480d6e3464f339ede102fc5bcb078",
      "max": 615,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0a39ec610ffc4a95a03596e144a0f905",
      "value": 615
     }
    },
    "3208741436df4f07a8652362a451cdc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2fd0d94669c34ac2b2825fbf166202ec",
      "placeholder": "â",
      "style": "IPY_MODEL_83b84f2fa4b440bea43222657938b3c2",
      "value": "â615/615â[00:03&lt;00:00,â162.99âexamples/s]"
     }
    },
    "72f1364c8b4747c9a424f9e5070f233c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a93afd633054cf5b4ae6b1d9aa75ba1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc4a9f166c674e15a05d2093c4378e7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ff480d6e3464f339ede102fc5bcb078": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a39ec610ffc4a95a03596e144a0f905": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2fd0d94669c34ac2b2825fbf166202ec": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83b84f2fa4b440bea43222657938b3c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
